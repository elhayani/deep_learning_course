# Deep Learning : De Zéro à la Certification Tensorflow

Apprendre l’Intelligence Artificielle avec Tensorflow et passer l’examen Tensorflow developer Certification de Google.

Suivre la formation sur [Udemy](https://www.udemy.com/course/deep-learning-de-zero-a-la-certification-tensorflow/?referralCode=736CA5E82E8C3418B458)

# Curriculum de la formation

## Les Fondamentaux du Deep Learning

- Introduction au Deep Learning
- Les Vecteurs et Matrices
- Les Tenseurs et Numpy
- Les Fonctions en maths avec du code
- Le concept de dérivée
- Fonctions composées et dérivés de fonctions composés
- Produit matriciel et Numpy
- Dérivée d’un produit matriciel
- Le paramètre biais
- L’algorithme du Gradient Descent avec Numpy
- La Régression linéaire de zéro avec Numpy
- La fonction sigmoid

## Recréer Tensorflow

- Qu’est-ce-que Tensorflow et Plan de création
- L’architecture du Mini Tensorflow
- La classe Noeud
- La classe Noeud avec des paramètres
- La classe Layer (les couches du réseau de neurones)
- La classe Loss (La fonction perte)
- La classe Optimizer (La fonction d’optimisation)
- Tout mettre ensemble avec la classe Model (compile, fit, predict, evaluate)
- Entraîner un réseau de neurone avec Mini Tensorflow
- Sauvegarder et charger un modèle entrainé
- De Mini Tensorflow à Tensorflow

## Deep Learning pour la classification d’Image 

- La fonction softmax
- La fonction perte Cross entropy
- Les fonctions d’activations (relu, tanh, leaky relu)
- Le concept de Momentum
- Early stopping et les callbacks
- Le concept de Dropout pour éviter le surapprentissage

## Les réseaux de neurones convolutionnels CNN pour la classification d’image

- Les convolutions : Intuition et explication
- Le Padding et le Pooling
- Implémenter un CNN avec Tensorflow
- Le Data Augmentation pour de meilleurs performances
- Le Transfert Learning (Extraction de features et Fine tuning)
- Streamlit APP

## Introduction au Natural Language Processing

- Passer du texte aux nombres (Vectorisation)
- La tokenisation et le nettoyage du texte
- Encoder la signification des mots grâce aux embeddings
- Implémenter un couche Embedding avec Tensorflow

## La classification du texte avec les réseaux de neurones récurrents RNN et LSTM

- Les RNN : Intuition et Explication
- Les réseaux Long Short Term Memory : Intuition et Explication
- Analyser le sentiment d’un texte avec un réseau LSTM
- Les LSTM bidirectionnels pour une meilleure performance
- Transfert Learning : Utiliser des embeddings pré-entrainés


## Utiliser Tensorflow pour entraîner un modèle générateur de texte : BibleGPT

- Modèles générateurs de Texte : Intuition
- Créer le dataset pour l’entrainement du modèle (BibleGPT)
- Architecture et Entrainement du modèle
- Prédiction du prochain mot avec le modèle de génération de Texte

## Prédire le futur avec le Deep Learning sur les séries temporelles

- Les attributs des séries temporelles (trend, seasonality, autocorrection, Noise)
- Techniques pour prédiction des séries temporelles
- Créer des Modèles de deep learning pour la prédiction des séries Temporelles
- Appliquer les CNN, RNN, LSTM, GRU pour la prédiction des séries temporelles

## Astuces pour réussir l’examen de certification de Tensorflow

- Comment se préparer pour l'examen
- Configurer son environnement pour l'examen
- Ressources supplémentaires


By [Kevin Degila](https://youtube.com/kevindegila)